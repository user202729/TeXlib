%! TEX program = pdflatex
\documentclass[a5paper]{article}
\errorcontextlines=5
\usepackage{prettytok}
\prettyinitterm

\ifdefined\prettyinittermcat
	\prettyinittermcat
\fi

\ExplSyntaxOn
\pretty:n{going to load}
\ExplSyntaxOff

\makeatletter
\let\firstoftwo\@firstoftwo
\let\secondoftwo\@secondoftwo
\makeatother

\unless\ifdefined\specifymode
	\def\specifymode{unnamed-pipe}
\fi

\def\tmp#1{
	\usepackage[mode=#1,python-executable={PYTHONPATH=/home/user202729/TeX/pythonimmediate/ python3.8}]{pythonimmediate}
}
\expandafter\tmp\expandafter{\specifymode}

%\usepackage[mode=unnamed-pipe]{pythonimmediate}








\ExplSyntaxOn
\pretty:n{1.start}

\begin{pycode}
import pythonimmediate

x="xxx"
import sys
print("======== test stdout ========")
print("======== test stderr ========", file=sys.stderr)

#print=pythonimmediate.print
printT=pythonimmediate.print
pythonimmediate.run_tokenized_line_local(r'\pretty:n {2.a}')
\end{pycode}

\pycv|pythonimmediate.run_block_local(r'\pretty:n {3.xxx~ =~ ' + x + '}')|

\begin{pycode}
pythonimmediate.run_block_local(r'''
\pretty:n {4.}
\pycv|pythonimmediate.run_tokenized_line_local(r'\pretty:n{5.}')|
\pretty:n {6.}
''')
\end{pycode}

\begin{pycode}

x=123

pythonimmediate.run_tokenized_line_peek(
r'\pretty:n{7.} \pyc{x=456} \pretty:n{8.} \pythonimmediatecontinue {}'
)

assert x==456

content=pythonimmediate.run_tokenized_line_peek(r'\pythonimmediatecontinue {abc~~def}')
assert "abc def"==content, content

pythonimmediate.run_tokenized_line_local(
r'\pretty:n{9.}'
)
\end{pycode}

\pretty:n{10.}


\ExplSyntaxOff


\begin{document}




1+1=\py{1+1}.

\pyc{x=3}

x=\py{x}.

% \pyc{printT("%")}  % â† error!

x=\pyc{printT(str(x), end="")}.  % without trailing space. Note that this requires % to have the "comment" catcode.

x=\pyc{printT(str(x))}.  % there's an extra space.

\begin{pycode}
print("11.\n")
\end{pycode}

% ======== test empty code block
\begin{pycode}
\end{pycode}


\begin{pycode}


import unittest
from pythonimmediate import Token, TokenList, BalancedTokenList, Catcode, ControlSequenceToken, frozen_relax_token, BlueToken, NTokenList
from pythonimmediate import Catcode as C
T=ControlSequenceToken.make

engine: str=T.c_sys_engine_str.value_str()
assert engine in ["pdftex", "xetex", "luatex"]
is_unicode: bool=engine in ["xetex", "luatex"]

class Test(unittest.TestCase):
	def test_simple_run_tokenized_line_local(self)->None:
		pythonimmediate.run_tokenized_line_local(r'\testa {123} {456}')
		self.assertEqual(x, "123")
		self.assertEqual(y, "456")

	def test_renewcommand_non_Python_defined(self):
		pythonimmediate.run_tokenized_line_local(r'\def \testb {}')

		@pythonimmediate.renewcommand
		def testb(): pass


	def test_preserve_spaces(self)->None:
		self.assertEqual("""
   
""".count(' '), 3)

	def test_newcommand(self):
		global x
		x=1

		@pythonimmediate.newcommand
		def testa():
			global x
			x=2

		self.assertEqual(x, 1)
		pythonimmediate.run_tokenized_line_local(r'\testa')
		self.assertEqual(x, 2)

	def test_unicode_str(self):
		s='Ã†Â²Ã—â´â„ð•'
		pythonimmediate.put_next('{' + s + '}')
		self.assertEqual(pythonimmediate.get_arg_str(), s)

		pythonimmediate.put_next('{' + s + '}')
		self.assertEqual(pythonimmediate.get_arg_estr(), s)

	def test_hash(self):
		for put, get in [
				("#", None),
				("#1#2#3##", None),
				(r"\#", None),
				(r"\##", None),
				(r"#\#", None),
				]:
			pythonimmediate.put_next('{' + put + '}')
			self.assertEqual(pythonimmediate.get_arg_str(), (put if get is None else get))


	def test_newcommand_with_name(self):
		@pythonimmediate.newcommand("testd")
		def testa():
			global x
			x=3

		self.assertEqual(x, 2)
		pythonimmediate.run_tokenized_line_local(r'\testd')
		self.assertEqual(x, 3)

		@pythonimmediate.renewcommand
		def testa():
			global x, y
			x=pythonimmediate.get_arg_str()
			y=pythonimmediate.get_arg_str()

		@pythonimmediate.newcommand
		def testc():
			self.assertEqual(pythonimmediate.get_arg_str(), "ab")
			self.assertEqual(pythonimmediate.get_optional_arg_str(), "cd")
			self.assertEqual(pythonimmediate.get_optional_arg_str(), None)
			self.assertEqual(pythonimmediate.get_verb_arg(), "ef")
			self.assertEqual(pythonimmediate.get_optional_arg_str(), None)
			self.assertEqual(pythonimmediate.get_verb_arg(), "gh")
			self.assertEqual(pythonimmediate.get_multiline_verb_arg(), "ijk\nlm")
			printT("123", end="")
			return "456"

		pythonimmediate.run_tokenized_line_local("789%")
		pythonimmediate.run_tokenized_line_local("789%")

		# TODO temporary skip
		if engine!="xetex":
			pythonimmediate.run_block_local(r'''\testc {ab} [cd]|ef|{gh}|ijk
			lm|%''')

		pythonimmediate.run_tokenized_line_local("789%")


	def test_tokens(self):
		global x
		x=0

		@pythonimmediate.renewcommand
		def testd():
			global x
			x=1

			a=BalancedTokenList.get_next()

			pythonimmediate.put_next(r'{123}')
			b=BalancedTokenList.get_next()

			pythonimmediate.put_next(r'{1 a\relax}')
			for t, meaning in [
					(Catcode.bgroup('{'), "begin-group character {"),
					(Catcode.other ('1'), "the character 1"),
					(Catcode.space (' '), "blank space  "),
					(Catcode.letter('a'), "the letter a"),
					(ControlSequenceToken('relax'), r"\relax"),
					(Catcode.egroup('}'), "end-group character }"),
					]:
				self.assertEqual(pythonimmediate.peek_next_meaning(), meaning)
				self.assertEqual(pythonimmediate.Token.peek_next(), t)
				self.assertEqual(pythonimmediate.Token.get_next(), t)


			a.put_next()
			c=BalancedTokenList.get_next()

			self.assertEqual(c, a[1:-1])


		self.assertEqual(x, 0)
		pythonimmediate.run_block_local(
		r'''
		\precattlExec{ \testd {{ab\cC {}\cC{123}\relax\cFrozenRelax {}\cP*$^_ \cS\a}} }
		''')
		self.assertEqual(x, 1)

	def test_tokens2(self):
		for t in [
				frozen_relax_token,
				ControlSequenceToken(">>"),
				ControlSequenceToken(""),
				ControlSequenceToken("  "),
				ControlSequenceToken(" > a b>\\> "),
				Catcode.space(' '),
				Catcode.other(' '),
				Catcode.letter(' '),
				Catcode.space('\\'),
				Catcode.other('\\'),
				Catcode.letter('\\'),
				Catcode.bgroup(' '),
				Catcode.egroup(' '),
				]:
			with self.subTest(t=t):
				t.put_next()
				self.assertEqual(Token.peek_next(), t)
				self.assertEqual(Token.get_next(), t)

	def test_tokens_control_chars(self):
		# TODO later handle upper bytes for non-Unicode engines as well
		for s in [
				chr(i)
				for i in range(0, (700 if is_unicode else 256))
				]:
			for t in [
				Catcode.active(s),
				Catcode.bgroup(s),
				Catcode.egroup(s),
				Catcode.other (s),
				ControlSequenceToken(s),
				ControlSequenceToken(s+s),
				]:
				if engine=="luatex" and t in [ControlSequenceToken("\x00"), ControlSequenceToken("\x00\x00")]:
					continue  # LuaTeX bug fixed upstream https://tex.stackexchange.com/questions/640267/lualatex-does-not-handle-control-sequence-consist-of-a-single-null-character-cor
				if engine=="pdftex" and t==Catcode.active(0x0c):
					continue  # https://tex.stackexchange.com/q/669877/250119

				with self.subTest(s=s, t=t):
					pythonimmediate.debug("trying token", t)
					t.put_next()
					self.assertEqual(Token.get_next(), t)

	def test_put_get_next(self):
		pythonimmediate.put_next("a")
		self.assertEqual(pythonimmediate.peek_next_char(), "a")

		pythonimmediate.put_next(r"\a")
		self.assertEqual(pythonimmediate.peek_next_char(), "")
		pythonimmediate.Token.get_next()

		pythonimmediate.CharacterToken(ord(' '), pythonimmediate.Catcode.space).put_next()
		self.assertEqual(pythonimmediate.peek_next_char(), " ")

		pythonimmediate.put_next(r"\relax")
		self.assertEqual(pythonimmediate.peek_next_char(), "")

		pythonimmediate.put_next(r"\begingroup\endgroup")
		self.assertEqual(pythonimmediate.peek_next_char(), "")

		pythonimmediate.put_next(r"\bgroup\egroup")
		self.assertEqual(pythonimmediate.peek_next_char(), "{")

	def test_balanced(self):
		a=TokenList.doc(r'}{')
		self.assertFalse(a.is_balanced())
		with self.assertRaises(ValueError):
			a.check_balanced()

	def test_get_next_tokenlist(self):
		t=BalancedTokenList.doc(r'{}abc:  d?&#^_\test+\test a\##') + [frozen_relax_token]
		u=BalancedTokenList([t])
		self.assertEqual(len(u), len(t)+2)
		u.put_next()
		self.assertEqual(BalancedTokenList.get_next(), t)


	def test_from_str(self):
		self.assertEqual(TokenList.doc(r'}{abc:  d?&#^_\test+\test a\##'),
			  TokenList([
				  C.egroup("}"),
				  C.bgroup("{"),
				  C.letter("a"),
				  C.letter("b"),
				  C.letter("c"),
				  C.other(":"),
				  C.space(" "),
				  C.letter("d"),
				  C.other("?"),
				  C.alignment("&"),
				  C.parameter("#"),
				  C.superscript("^"),
				  C.subscript("_"),
				  ControlSequenceToken("test"),
				  C.other("+"),
				  ControlSequenceToken("test"),
				  C.letter("a"),
				  ControlSequenceToken("#"),
				  C.parameter("#"),
				  ]))
		self.assertEqual(TokenList.e3(r'abc:  d~?&#^_\test+\test a'),
			  TokenList([
				  C.letter("a"),
				  C.letter("b"),
				  C.letter("c"),
				  C.letter(":"),
				  C.letter("d"),
				  C.space(" "),
				  C.other("?"),
				  C.alignment("&"),
				  C.parameter("#"),
				  C.superscript("^"),
				  C.letter("_"),
				  ControlSequenceToken("test"),
				  C.other("+"),
				  ControlSequenceToken("test"),
				  C.letter("a"),
				  ]))

	def test_balanced_parts(self):
		for s in [
				r"",
				r"}{",
				r"ab{cd}ef}{gh}{{ij}",
				r"}}}}}{{{",
				r"{{{}}}}}",
				]:
			t=TokenList.doc(s)
			parts=t.balanced_parts()
			self.assertEqual(t, [x for part in parts for x in (part if isinstance(part, BalancedTokenList) else [part])])
			for part in parts:
				if isinstance(part, Token):
					self.assertNotEqual(part.degree(), 0)
				else:
					self.assertNotEqual(len(part), 0)

			t.put_next()
			for x in t:
				self.assertEqual(Token.get_next(), x)

	def test_expand(self):
		BalancedTokenList.doc(r'\def\testexpand{\testexpanda}\def\testexpanda{123}').execute()
		self.assertEqual(BalancedTokenList.doc(r'\testexpand').expand_o(), BalancedTokenList.doc(r'\testexpanda'))
		self.assertEqual(BalancedTokenList.doc(r'\testexpand').expand_x(), BalancedTokenList.doc(r'123'))
		self.assertEqual(BalancedTokenList.doc(' ').expand_o(), BalancedTokenList.doc(' '))
		self.assertEqual(BalancedTokenList.doc(' ').expand_x(), BalancedTokenList.doc(' '))
		self.assertEqual(1, len(BalancedTokenList.doc(' ')))
		self.assertEqual(BalancedTokenList([frozen_relax_token]).expand_x(), BalancedTokenList([frozen_relax_token]))
		self.assertEqual(TokenList.doc(r'\string}\string{\number`{').expand_x().str(), "}{123")

	def test_get_arg_estr(self):
		BalancedTokenList.doc(r'{123}').put_next()
		self.assertEqual(pythonimmediate.get_arg_estr(), "123")

		BalancedTokenList.doc(r'{\empty}').put_next()
		self.assertEqual(pythonimmediate.get_arg_estr(), "")

		BalancedTokenList.doc(r'{a\ \\\{\}\$\&\#\^\_\%\~~b}').put_next()
		self.assertEqual(pythonimmediate.get_arg_estr(), r"a \{}$&#^_%~~b")

		
	def test_get_optional_arg_estr(self):
		BalancedTokenList.doc(r'[123]').put_next()
		self.assertEqual(pythonimmediate.get_optional_arg_estr(), "123")

		# outermost only {} get stripped
		BalancedTokenList.doc(r'[{123}]').put_next()
		self.assertEqual(pythonimmediate.get_optional_arg_estr(), "123")

		# can also be used to hide the ]
		BalancedTokenList.doc(r'[{]}]').put_next()
		self.assertEqual(pythonimmediate.get_optional_arg_estr(), "]")

		# can also hide this way
		BalancedTokenList.doc(r'[\]]').put_next()
		self.assertEqual(pythonimmediate.get_optional_arg_estr(), "]")

		# test expansion
		BalancedTokenList.doc(r'[\empty]').put_next()
		self.assertEqual(pythonimmediate.get_optional_arg_estr(), "")

		# test balancedness & keep braces (supported by xparse)
		BalancedTokenList.doc(r'[{a}\ \\\{\}\$\&\#\^\_\%\~~b[]]').put_next()
		self.assertEqual(pythonimmediate.get_optional_arg_estr(), r"{a} \{}$&#^_%~~b[]")

		# test nonexistent optional argument
		BalancedTokenList.doc(r'{ab}').put_next()
		self.assertEqual(pythonimmediate.get_optional_arg_estr(), None)
		self.assertEqual(pythonimmediate.get_arg_str(), "ab")

	def test_control_sequence_token_maker(self):
		self.assertEqual(ControlSequenceToken("ab_c"), ControlSequenceToken.make.ab_c)
		self.assertEqual(ControlSequenceToken("ab_c"), ControlSequenceToken.make["ab_c"])

	def test_expand_once(self):
		BalancedTokenList.doc(r'\def\aaa{\bbb}').execute()
		T.aaa.put_next()
		pythonimmediate.expand_once()
		self.assertEqual(Token.get_next(), T.bbb)

	def test_blue_tokens(self):
		self.assertEqual(
				T.empty.meaning_str(),
				"macro:->")
		self.assertIn(
				T.empty.blue.meaning_str(),
				[r"\relax", r"[unknown command code! (0, 1)]"])

	def test_meaning_equal(self):
		self.assertFalse(T.empty.blue.meaning_equal(T.empty))
		self.assertFalse(T.empty.meaning_equal(T.empty.blue))
		self.assertTrue(T.relax.blue.meaning_equal(T.relax))
		self.assertTrue(T.empty.blue.meaning_equal(T.empty.blue))

	def test_assign_to_blue(self):
		NTokenList([T.let, T.aaa.blue, T.ifx]).execute()
		self.assertTrue(T.aaa.meaning_equal(T.ifx))

		NTokenList([T.futurelet, T.aaa.blue, T["@gobble"], T.ifcat]).execute()
		self.assertTrue(T.aaa.meaning_equal(T.ifcat))

	def test_make_tokenlist_from_blue(self):
		with self.assertRaises(RuntimeError):
			TokenList([T.aaa.blue])

	def test_assign(self):
		for t in [T.ifx, T.ifx.blue, C.other("="), C.space(' '), T.empty, T.relax, T.empty.blue]:
			with self.subTest(t=t):
				T.aaa.assign(t)
				self.assertTrue(T.aaa.meaning_equal(t))

				t.put_next()
				T.aaa.assign_future()
				self.assertTrue(T.aaa.meaning_equal(t))

				T.aaa.assign(T.empty)

				T.empty.put_next()
				T.aaa.assign_futurenext()
				self.assertTrue(T.aaa.meaning_equal(t.no_blue))

				assert Token.get_next()==T.empty
				assert Token.get_next()==t.no_blue

				T.aaa.assign(T.empty)

				NTokenList([T.empty, t]).put_next()
				T.aaa.assign_futurenext()
				self.assertTrue(T.aaa.meaning_equal(t))

				assert Token.get_next()==T.empty
				assert Token.get_next()==t.no_blue

	def test_outer_token(self)->None:
		TokenList.doc(r"\outer\def\outertest{}").execute()

		self.assertEqual(
				TokenList.doc(r"\string}\string}\string\outertest\string{\string{").expand_x().str(),
				r"}}\outertest{{")

		T.outertest.put_next()
		self.assertEqual(Token.get_next(), T.outertest)

	def test_deserialize_not_accidentally_define(self)->None:
		self.assertEqual(
				TokenList.doc(r'\meaning\undefined').expand_x().str(),
				r'undefined')


suite = unittest.defaultTestLoader.loadTestsFromTestCase(Test)
result = unittest.TextTestRunner(failfast=True).run(suite)
assert not result.errors

x=y=z=1
\end{pycode}

\def\testFilePath{test_pythonimmediate_file.py}
\def\letYThree{y=3}
\def\letZFour{z=4}

% ======== test indirect execution
\pyfile{\testFilePath}  % x=2
\pyc{\letYThree}
\pycq{\letZFour}

\begin{pycode}
assert x==2
assert y==3
assert z==4
x=y=z=1
\end{pycode}

% ======== test direct execution
\pyfile{test_pythonimmediate_file.py}  % x=2
\pyc{y=3}
\pycq{z=4}

\begin{pycode}
assert x==2
assert y==3
assert z==4
x=y=z=1
\end{pycode}

% ======== test more symbols
\pyc{assert ord(r' ')   ==0x20}
\pyc{assert ord(r'\ ')  ==0x20}
\pyc{assert len(r'  ')  ==1}  % unfortunate
\pyc{assert len(r'\ \ ')==2}
\pyc{assert ord('\\\\')==0x5c}
\pyc{assert ord(r'\{')  ==0x7b}
\pyc{assert ord(r'\}')  ==0x7d}
\pyc{assert ord(r'\$')  ==0x24}
\pyc{assert ord(r'$')   ==0x24}
\pyc{assert ord(r'\&')  ==0x26}
\pyc{assert ord(r'&')   ==0x26}
\pyc{assert len(r'#')   ==2}  % unfortunate
\pyc{assert len(r'\#')  ==1}
\pyc{assert ord(r'\#')  ==0x23}
\pyc{assert ord(r'^')   ==0x5e}
\pyc{assert ord(r'\^')  ==0x5e}
\pyc{assert ord(r'_')   ==0x5f}
\pyc{assert ord(r'\_')  ==0x5f}
\pyc{assert ord(r'\%')  ==0x25}
\pyc{assert ord(r'~')   ==0x7e}
\pyc{assert ord(r'\~')  ==0x7e}

\end{document}
